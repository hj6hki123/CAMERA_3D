{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c859a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached memory_vec (datasets/temp_corpus.jsonl.pt)\n",
      "✓ Load cached FAISS index & tokens from ckpts_0530\n",
      "ds.items[0].obj_id = 00026607d2024fb8888e85791310ed52, idx0 = 11\n",
      " all_tok[idx0].shape = (14, 512)\n",
      "ds.items[10].obj_id = 00026607d2024fb8888e85791310ed52, idx0 = 11\n",
      " all_tok[idx0].shape = (14, 512)\n",
      "ds.items[123].obj_id = 002823d4334b42cc9a5bb9be0884c71a, idx0 = 131\n",
      " all_tok[idx0].shape = (14, 512)\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, faiss\n",
    "from datasets.unified_dataset import UnifiedDataset\n",
    "from models.rag_text_encoder import RAGTextEncoder\n",
    "from models.gf_mv_encoder import GFMVEncoder\n",
    "from train_two_stage import build_faiss_with_tok\n",
    "\n",
    "# 1. 先随便把 ds、txt_enc、vis_enc 都 load 了\n",
    "ds = UnifiedDataset(\"datasets/unified_data.jsonl\", num_views=12)\n",
    "ckpt = torch.load(\"ckpts_0530/enc1.pth\", map_location=\"cpu\")\n",
    "txt_enc = RAGTextEncoder(\"datasets/unified_data.jsonl\", top_k=4).cpu().eval()\n",
    "vis_enc = GFMVEncoder(num_views=12).cpu().eval()\n",
    "txt_enc.load_state_dict(ckpt[\"txt\"])\n",
    "vis_enc.load_state_dict(ckpt[\"vis\"])\n",
    "\n",
    "# 2. Build / load faiss_index + all_tok\n",
    "class Args: pass\n",
    "args = Args()\n",
    "args.bs    = 16\n",
    "args.out   = \"ckpts_0530\"\n",
    "args.views = 12\n",
    "index, all_tok = build_faiss_with_tok(ds, txt_enc, vis_enc, args)\n",
    "\n",
    "# 3. 随机抽 3 个 obj_id，比对一下：\n",
    "for i in [0, 10, 123]:\n",
    "    oid = ds.items[i][\"obj_id\"]\n",
    "    # 先找它在 obj2idx：\n",
    "    idx0 = ds.obj2idx[oid]\n",
    "    # 再直接 load all_tok[idx0]，让它 encode 一遍 imgs 看看和 vis_enc( imgs ) 结果是不是一模一样\n",
    "    # 这里只用最简单的 L2 差距来瞄一眼\n",
    "    #   imgs0 = 原始图片 → vis_enc(imgs0) = vis_tok0\n",
    "    print(f\"ds.items[{i}].obj_id = {oid}, idx0 = {idx0}\")\n",
    "    # 顺便看一下 all_tok[idx0] 的 shape\n",
    "    print(\" all_tok[idx0].shape =\", all_tok[idx0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d0b995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached memory_vec (datasets/temp_corpus.jsonl.pt)\n",
      "✓ Load cached FAISS index & tokens from ckpts_0530\n",
      " b=0: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      " b=1: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      " b=2: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      " b=3: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      " b=4: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      " b=5: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      " b=6: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      " b=7: obj_id[b]=00026607d2024fb8888e85791310ed52, FAISS top1 obj_id=00026607d2024fb8888e85791310ed52\n",
      "Dataset unique obj_id count: 7369\n",
      "前10筆 obj_id： ['00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52', '00026607d2024fb8888e85791310ed52']\n"
     ]
    }
   ],
   "source": [
    "import os, torch, faiss, numpy as np\n",
    "from datasets.unified_dataset      import UnifiedDataset\n",
    "from models.rag_text_encoder       import RAGTextEncoder\n",
    "from models.gf_mv_encoder          import GFMVEncoder\n",
    "from train_two_stage               import build_faiss_with_tok\n",
    "\n",
    "# 1. 准备\n",
    "ds = UnifiedDataset(\"datasets/unified_data.jsonl\", num_views=12)\n",
    "ckpt = torch.load(\"ckpts_0530/enc1.pth\", map_location=\"cpu\")\n",
    "txt_enc = RAGTextEncoder(\"datasets/unified_data.jsonl\", top_k=4).cpu().eval()\n",
    "vis_enc = GFMVEncoder(num_views=12).cpu().eval()\n",
    "txt_enc.load_state_dict(ckpt[\"txt\"])\n",
    "vis_enc.load_state_dict(ckpt[\"vis\"])\n",
    "\n",
    "args = type(\"A\", (), {})()\n",
    "args.bs = 8\n",
    "args.out = \"ckpts_0530\"\n",
    "args.views = 12\n",
    "\n",
    "index, all_tok = build_faiss_with_tok(ds, txt_enc, vis_enc, args)\n",
    "\n",
    "# 2. 随机拿一个 batch，手动看 FAISS 返回的 top‐1 跟 obj_id[b] 有没有对上\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=8, shuffle=False)\n",
    "for cap_batch, img_batch, oid_batch in loader:\n",
    "    # 只做第一个 batch 检查就够了\n",
    "    q_vec, _, txt_tok = txt_enc(list(cap_batch), list(oid_batch))\n",
    "    _, vis_tok = vis_enc(img_batch, q_vec)\n",
    "    sims, idx = index.search(q_vec.detach().cpu().numpy(), 50)\n",
    "    for b, oid in enumerate(oid_batch):\n",
    "        faiss_top1_idx = idx[b][0]\n",
    "        faiss_top1_obj = ds.items[faiss_top1_idx][\"obj_id\"]\n",
    "        print(f\" b={b}: obj_id[b]={oid}, FAISS top1 obj_id={faiss_top1_obj}\")\n",
    "    break\n",
    "print(\"Dataset unique obj_id count:\", len(set(item[\"obj_id\"] for item in ds.items)))\n",
    "print(\"前10筆 obj_id：\", [item[\"obj_id\"] for item in ds.items[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ff288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached memory_vec (datasets/temp_corpus.jsonl.pt)\n",
      "✓ Load cached FAISS index & tokens from ckpts_0530\n",
      "\n",
      ">>> b=0:  batch 的 obj_id = 00026607d2024fb8888e85791310ed52 ; FAISS top1 obj_id = 00026607d2024fb8888e85791310ed52\n",
      "   reranker(pos scores) = [0.1545835 0.1545835 0.1545835]\n",
      "   reranker(neg scores) = [0.15543418 0.15626474 0.15581958]\n"
     ]
    }
   ],
   "source": [
    "import os, torch, faiss, numpy as np\n",
    "from datasets.unified_dataset      import UnifiedDataset\n",
    "from models.rag_text_encoder       import RAGTextEncoder\n",
    "from models.gf_mv_encoder          import GFMVEncoder\n",
    "from models.cross_modal_reranker   import CrossModalReranker\n",
    "from train_two_stage               import build_faiss_with_tok\n",
    "\n",
    "ds = UnifiedDataset(\"datasets/unified_data.jsonl\", num_views=12)\n",
    "ckpt = torch.load(\"ckpts_0530/enc1.pth\", map_location=\"cpu\")\n",
    "txt_enc = RAGTextEncoder(\"datasets/unified_data.jsonl\", top_k=4).cpu().eval()\n",
    "vis_enc = GFMVEncoder(num_views=12).cpu().eval()\n",
    "txt_enc.load_state_dict(ckpt[\"txt\"])\n",
    "vis_enc.load_state_dict(ckpt[\"vis\"])\n",
    "\n",
    "args = type(\"A\", (), {})()\n",
    "args.bs = 4\n",
    "args.out = \"ckpts_0530\"\n",
    "args.views = 12\n",
    "args.L = 50\n",
    "\n",
    "index, all_tok = build_faiss_with_tok(ds, txt_enc, vis_enc, args)\n",
    "\n",
    "# 只看第一批\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=4, shuffle=False)\n",
    "for cap_batch, img_batch, oid_batch in loader:\n",
    "    q_vec, _, txt_tok = txt_enc(list(cap_batch), list(oid_batch))\n",
    "    _, vis_tok     = vis_enc(img_batch, q_vec)\n",
    "    vis_tok = torch.nn.functional.normalize(vis_tok, 2, -1)\n",
    "\n",
    "    sims, idx = index.search(q_vec.detach().cpu().numpy(), args.L)\n",
    "\n",
    "    # 下面开始做 s_pos / s_neg\n",
    "    reranker = CrossModalReranker().cpu().eval()\n",
    "    # 如果你已经有微调好 weights，就在这里 load\n",
    "    # reranker.load_state_dict(torch.load(\"ckpts_0530/rerank.pth\", map_location=\"cpu\"))\n",
    "\n",
    "    for b, oid in enumerate(oid_batch):\n",
    "        faiss_top1_idx = idx[b][0]\n",
    "        faiss_top1_obj = ds.items[faiss_top1_idx][\"obj_id\"]\n",
    "        # 1) 先印出应该是正例的那一行 VAIS idx\n",
    "        print(f\"\\n>>> b={b}:  batch 的 obj_id = {oid} ; FAISS top1 obj_id = {faiss_top1_obj}\")\n",
    "\n",
    "        # 2) 现在我们拿 out-of-sample 正例 token、和 N 个负例 token\n",
    "        #    `vis_tok[b]` 应该是 “batch 中第 b 笔 query” 的视觉 token\n",
    "        tok_pos = vis_tok[b : b+1]        # shape = (1, T_vis, 512)\n",
    "        t_pos   = txt_tok[b : b+1]        # shape = (1, 1+top_k, 768)\n",
    "\n",
    "        # 将 pos token 扩展成跟负例数一样多的行\n",
    "        # 建一个 (1 + (L-1)) 的组合：第一行是正例，后面都是负例\n",
    "        # 负例来自 all_tok[idx[b][1:]]  <-- idx[b][0] 是正例\n",
    "        neg_idx_list = idx[b][1 : 1+3]  # 先拿 3 个负例来 demo\n",
    "        tok_neg = torch.from_numpy(all_tok[neg_idx_list]).detach().cpu().float()  # shape = (3, T_vis, 512)\n",
    "        # t_pos_expand: (3, 1+top_k, 768)\n",
    "        t_pos_rep = t_pos.expand(len(neg_idx_list), -1, -1)\n",
    "\n",
    "        # 3) 把这 1:3 的 pos vs neg 一起丢给 reranker 看分数\n",
    "        x_pos = reranker(t_pos_rep, tok_pos.expand(len(neg_idx_list), -1, -1))  # shape = (3,)\n",
    "        x_neg = reranker(t_pos_rep, tok_neg)  # shape = (3,)\n",
    "\n",
    "        print(\"   reranker(pos scores) =\", x_pos.detach().numpy())\n",
    "        print(\"   reranker(neg scores) =\", x_neg.detach().numpy())\n",
    "\n",
    "        # 如果正例分数没比 3 个负例都高，就说明「正负对齐」或「loss 计算」有问题\n",
    "        break\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "part2point",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
